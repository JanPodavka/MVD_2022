{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MVD 5. cvičení\n",
    "\n",
    "## 1. část - TF-IDF s word embeddingy\n",
    "\n",
    "V minulém cvičení bylo za úkol implementovat TF-IDF algoritmus nad datasetem z Kagglu. Dnešní cvičení je rozšířením této úlohy s použitím word embeddingů. Lze použít předtrénované GloVe embeddingy ze 3. cvičení, nebo si v případě zájmu můžete vyzkoušet práci s Word2Vec od Googlu (najdete [zde](https://code.google.com/archive/p/word2vec/)).\n",
    "\n",
    "Cvičení by mělo obsahovat následující části:\n",
    "- Načtení článků a embeddingů\n",
    "- Výpočet document vektorů pomocí TF-IDF a word embeddingů \n",
    "    - Pro výpočet TF-IDF využijte [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) z knihovny sklearn\n",
    "    - Vážený průměr GloVe / Word2Vec vektorů\n",
    "\n",
    "<center>\n",
    "$\n",
    "doc\\_vector = \\frac{1}{|d|} \\sum\\limits_{w \\in d} TF\\_IDF(w) glove(w)\n",
    "$\n",
    "</center>\n",
    "\n",
    "- Dotaz bude transformován stejně jako dokument\n",
    "\n",
    "- Výpočet relevance pomocí kosinové podobnosti\n",
    "<center>\n",
    "$\n",
    "score(q,d) = cos\\_sim(query\\_vector, doc\\_vector)\n",
    "$\n",
    "</center>\n",
    "\n",
    "### Načtení článků"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\podav\\anaconda3\\envs\\data_science\\lib\\site-packages\\spacy\\language.py:1895: UserWarning: [W123] Argument disable with value ['parser', 'ner'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 title  \\\n0    chatbots were the next big thing what happened...   \n1    python for data science 8 concepts you may hav...   \n2    automated feature engineering in python toward...   \n3    machine learning how to go from zero to hero f...   \n4     reinforcement learning from scratch insight data   \n..                                                 ...   \n332  you can build a neural network in javascript e...   \n333  artificial intelligence ai in 2018 and beyond ...   \n334  spiking neural networks the next generation of...   \n335  surprise neurons are now more complex than we ...   \n336   wth does a neural network even learn a newcom...   \n\n                                                  text  \n0    oh how the headlines blared chatbots were the ...  \n1    if you ve ever found yourself looking up the s...  \n2    machine learning is increasingly moving from h...  \n3    if your understanding of a i and machine learn...  \n4    want to learn about applied artificial intelli...  \n..                                                 ...  \n332  click here to share this article on linkedin s...  \n333  these are my opinions on where deep neural net...  \n334  everyone who has been remotely tuned in to rec...  \n335  one of the biggest misconceptions around is th...  \n336  i believe we all have that psychologist philos...  \n\n[337 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>chatbots were the next big thing what happened...</td>\n      <td>oh how the headlines blared chatbots were the ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>python for data science 8 concepts you may hav...</td>\n      <td>if you ve ever found yourself looking up the s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>automated feature engineering in python toward...</td>\n      <td>machine learning is increasingly moving from h...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>machine learning how to go from zero to hero f...</td>\n      <td>if your understanding of a i and machine learn...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>reinforcement learning from scratch insight data</td>\n      <td>want to learn about applied artificial intelli...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>you can build a neural network in javascript e...</td>\n      <td>click here to share this article on linkedin s...</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>artificial intelligence ai in 2018 and beyond ...</td>\n      <td>these are my opinions on where deep neural net...</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>spiking neural networks the next generation of...</td>\n      <td>everyone who has been remotely tuned in to rec...</td>\n    </tr>\n    <tr>\n      <th>335</th>\n      <td>surprise neurons are now more complex than we ...</td>\n      <td>one of the biggest misconceptions around is th...</td>\n    </tr>\n    <tr>\n      <th>336</th>\n      <td>wth does a neural network even learn a newcom...</td>\n      <td>i believe we all have that psychologist philos...</td>\n    </tr>\n  </tbody>\n</table>\n<p>337 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner']) # NLTK\n",
    "\n",
    "\n",
    "def normalize_data(db):\n",
    "    # set all to lowercase\n",
    "    db['text'] = db['text'].str.lower()\n",
    "    db['title'] = db['title'].str.lower()\n",
    "\n",
    "    # delete all special characters\n",
    "    db['text'] = db['text'].str.replace(r'\\W', ' ', regex=True)\n",
    "    db['title'] = db['title'].str.replace(r'\\W', ' ', regex=True)\n",
    "    # delete multiple spaces\n",
    "    db['text'] = db['text'].str.replace(r'\\s+', ' ', regex=True)\n",
    "    db['title'] = db['title'].str.replace(r'\\s+', ' ', regex=True)\n",
    "    return db\n",
    "\n",
    "\n",
    "#data load and normalize\n",
    "df = pandas.read_csv('articles.csv')\n",
    "df = df[['title', 'text']]\n",
    "df_norm = normalize_data(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Načtení embeddingů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
      " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
      " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
      " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
      " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
      "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
      "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
      " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
      " -1.1514e-01 -7.8581e-01]\n",
      "the\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "with open('glove.6B/glove.6B.50D.txt', encoding='utf8') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        data.append(line)\n",
    "word = []\n",
    "word2idx = {}\n",
    "vec = np.zeros((len(data),len(data[0].split(' '))-1))\n",
    "for i,item in enumerate(data):\n",
    "    splited = item.replace('\\n','').split(' ')\n",
    "    word.append(splited[0])\n",
    "    vec[i,:] = np.asarray(splited[1:])\n",
    "    word2idx[splited[0]] = i\n",
    "\n",
    "print(vec[0])\n",
    "print(word[0])\n",
    "print(word2idx['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TF-IDF + Word2Vec a vytvoření doc vektorů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Transformace dotazu a výpočet relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bonus - Našeptávání\n",
    "\n",
    "Bonusem dnešního cvičení je našeptávání pomocí rekurentních neuronových sítí. Úkolem je vytvořit jednoduchou rekurentní neuronovou síť, která bude generovat text (character-level přístup). \n",
    "\n",
    "Optimální je začít po dokončení cvičení k předmětu ANS, kde se tato úloha řeší. \n",
    "\n",
    "Dataset pro učení vaší neuronové sítě naleznete na stránkách [Yahoo research](https://webscope.sandbox.yahoo.com/catalog.php?datatype=l&guccounter=1), lze využít např. i větší [Kaggle dataset](https://www.kaggle.com/c/yandex-personalized-web-search-challenge/data) nebo vyhledat další dataset na [Google DatasetSearch](https://datasetsearch.research.google.com/).\n",
    "\n",
    "Vstupem bude rozepsaný dotaz a výstupem by měly být alespoň 3 dokončené dotazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}